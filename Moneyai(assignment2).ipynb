{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **Data Cleaning and Validation** **bold text**\n",
        "-Identify and Handle Missing or Inconsistent Data\n",
        "Steps:\n",
        "\n",
        "Load the dataset into a Pandas DataFrame.\n",
        "Check for missing values (NaN or empty entries) using .isnull() or .info().\n",
        "Decide how to handle missing values:\n",
        "For critical fields like Entry_Price or SL:\n",
        "Drop rows if missing values are significant and can't be imputed.\n",
        "Impute values based on statistical measures (e.g., mean, median) if appropriate.\n",
        "For non-critical fields: Replace missing values with placeholders like 'Unknown' or '0'.\n",
        "Standardize inconsistent values, such as ensuring numeric columns don't have text entries.\n",
        "\n",
        "\n",
        "-Check for Duplicate Records Steps:\n",
        "\n",
        "Identify duplicate rows using .duplicated(). Drop duplicates if they are redundant for analysis. Use the subset parameter to check for duplication in specific columns (e.g., Trade_ID, Entry_Time). Validate remaining data to ensure no critical information is lost"
      ],
      "metadata": {
        "id": "8bKByCGMBR4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/trading_data.csv'  # Update with your file path\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Step 1: Check for missing values\n",
        "print(\"Missing values per column:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Step 2: Handle missing values\n",
        "# Drop rows with missing values in 'Entry_Price' or 'SL'\n",
        "if 'Entry_Price' in data.columns and 'SL' in data.columns:\n",
        "    data = data.dropna(subset=['Entry_Price', 'SL'])\n",
        "\n",
        "# Check if 'Notes' column exists before filling missing values\n",
        "if 'Notes' in data.columns:\n",
        "    data['Notes'] = data['Notes'].fillna('Unknown')\n",
        "\n",
        "# Step 3: Convert columns to numeric where applicable\n",
        "# Ensure 'Entry_Price' and 'SL' are numeric\n",
        "if 'Entry_Price' in data.columns:\n",
        "    data['Entry_Price'] = pd.to_numeric(data['Entry_Price'], errors='coerce')\n",
        "if 'SL' in data.columns:\n",
        "    data['SL'] = pd.to_numeric(data['SL'], errors='coerce')\n",
        "\n",
        "# Drop rows with newly created NaNs due to invalid numeric conversion\n",
        "data = data.dropna(subset=['Entry_Price', 'SL'])\n",
        "\n",
        "# Step 4: Verify the changes\n",
        "print(\"Cleaned data preview:\")\n",
        "print(data.head())\n",
        "\n",
        "# Step 1: Check for duplicates\n",
        "duplicates = data[data.duplicated()]\n",
        "print(f\"Number of duplicate rows: {len(duplicates)}\")\n",
        "\n",
        "# Step 2: Drop duplicate rows\n",
        "data = data.drop_duplicates()\n",
        "\n",
        "# Optionally, drop duplicates based on specific columns (e.g., Trade_ID and Entry_Time)\n",
        "# data = data.drop_duplicates(subset=['Trade_ID', 'Entry_Time'])\n",
        "\n",
        "# Verify duplicates removal\n",
        "print(f\"Data after removing duplicates: {data.shape}\")\n"
      ],
      "metadata": {
        "id": "XzyvSl0LBSZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 *Data Summarization**\n",
        "\n",
        "-- Data Summarization\n",
        "Step 1: Calculate Total Profit/Loss\n",
        "The profit/loss can be calculated as the difference between Exit_Price and Entry_Price for all trades.\n",
        "Formula:\n",
        "Profit/Loss\n",
        "=\n",
        "(\n",
        "Exit_Price\n",
        "−\n",
        "Entry_Price\n",
        ")\n",
        "×\n",
        "Quantity\n",
        "Profit/Loss=(Exit_Price−Entry_Price)×Quantity\n",
        "\n",
        "--Create a Pivot Table\n",
        "Summarize the average SL% and Trgt% grouped by the Index column."
      ],
      "metadata": {
        "id": "W85TqXlKCq8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/trading_data.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Calculate profit/loss for each trade\n",
        "df['Profit_Loss'] = (df['Exit_Price'] - df['Entry_Price']) * df['Quantity']\n",
        "\n",
        "# Calculate total profit/loss\n",
        "total_profit_loss = df['Profit_Loss'].sum()\n",
        "print(f\"Total Profit/Loss: {total_profit_loss}\")\n",
        "\n",
        "# Create pivot table\n",
        "pivot_table = df.pivot_table(\n",
        "    values=['SL%', 'Trgt%'],\n",
        "    index='Index',\n",
        "    aggfunc='mean'\n",
        ")\n",
        "\n",
        "print(\"Pivot Table - Average SL% and Trgt% by Index:\")\n",
        "print(pivot_table)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "92utB-19CrQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Sorting and Filtering\n",
        "\n",
        "--Sort the data to show the top 10 trades by profit (or loss).Step 1: Sort Top 10 Trades by Profit/Loss\n",
        "Sort the trades by Profit_Loss in descending order to get the top 10 most profitable trades.\n",
        "Alternatively, sort in ascending order to get the top 10 biggest losses\n",
        "--Filter the data to display only trades that hit their SL or Target. Filter Trades That Hit SL or Target\n",
        "Filter rows where Hit_SL or Hit_Target column equals True."
      ],
      "metadata": {
        "id": "4I8r_RMTC5DL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/trading_data.csv')\n",
        "\n",
        "# Calculate profit or loss for each trade, considering quantity\n",
        "data['Profit/Loss'] = (data['Exit_Price'] - data['Entry_Price']) * data['Quantity']\n",
        "\n",
        "# Sort the dataset by profit/loss and display the top 10 trades\n",
        "sorted_data = data.sort_values(by='Profit/Loss', ascending=False).head(10)\n",
        "print(\"Top 10 trades by profit:\")\n",
        "print(sorted_data[['Index', 'Entry_Price', 'Exit_Price', 'Quantity', 'Profit/Loss']])\n",
        "\n",
        "# Ensure 'Exit_Reason' column is clean and standardized\n",
        "data['Exit_Reason'] = data['Exit_Reason'].str.strip().str.lower()\n",
        "\n",
        "# Filter trades that hit SL or Target based on 'Exit_Reason'\n",
        "sl_target_hits = data[data['Exit_Reason'].isin(['trgt_hit', 'straddle_max_loss_hit', 'max_loss_hit'])]\n",
        "print(\"\\nTrades that hit SL or Target:\")\n",
        "print(sl_target_hits[['Index', 'Exit_Reason', 'Entry_Price', 'Exit_Price', 'Quantity', 'Profit/Loss']])\n"
      ],
      "metadata": {
        "id": "YPGPOzw4C5Ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4 Performance Analysis**\n",
        "\n",
        "--Step 1: Calculate the Percentage of Trades That Hit SL vs. Target\n",
        "Count the total number of trades.\n",
        "Count how many trades hit SL and how many hit Target.\n",
        "Calculate the percentage using:\n",
        "Percentage\n",
        "=\n",
        "Count of SL or Target Trades\n",
        "Total Trades\n",
        "×\n",
        "100\n",
        "Percentage=\n",
        "Total Trades\n",
        "Count of SL or Target Trades\n",
        "​\n",
        "\n",
        "----Step 2: Group Data by Strategy and Determine Success Rate\n",
        "Group the data by the Strategy column.\n",
        "Define a \"successful trade\" as one that hits the target (i.e., Hit_Target == True).\n",
        "Calculate the success rate for each strategy:\n",
        "Success Rate\n",
        "=\n",
        "Number of Successful Trades\n",
        "Total Trades for Strategy\n",
        "×\n",
        "100\n",
        "Success Rate=\n",
        "Total Trades for Strategy\n",
        "Number of Successful Trades\n",
        "​\n",
        " ×100\n",
        "\n",
        " ---Step 3: Analyze Correlation Between VixEntry, VixExit, and Trade Outcomes\n",
        "Correlation indicates how strongly two variables are related (values range from -1 to 1).\n",
        "Use pandas.corr() to calculate the correlation between VixEntry, VixExit, and the Profit_Loss."
      ],
      "metadata": {
        "id": "vkRSfNjQKpZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_trades = len(data)\n",
        "\n",
        "# Count trades hitting SL and Target\n",
        "sl_hits = len(data[data['Exit_Reason'].isin(['straddle_max_loss_hit', 'max_loss_hit'])])\n",
        "target_hits = len(data[data['Exit_Reason'] == 'trgt_hit'])\n",
        "\n",
        "# Calculate percentages\n",
        "sl_percentage = (sl_hits / total_trades) * 100\n",
        "target_percentage = (target_hits / total_trades) * 100\n",
        "\n",
        "print(f\"\\nPercentage of trades that hit SL: {sl_percentage:.2f}%\")\n",
        "print(f\"Percentage of trades that hit Target: {target_percentage:.2f}%\")\n",
        "\n",
        "strategy_success = data.groupby('Strategy')['Profit/Loss'].mean()\n",
        "print(\"\\nSuccess rate by strategy (mean profit/loss):\")\n",
        "print(strategy_success)\n",
        "\n",
        "# Correlation between VixEntry/VixExit and trade outcomes\n",
        "correlation_matrix = data[['VixEntry', 'VixExit', 'Profit/Loss']].corr()\n",
        "print(\"\\nCorrelation between VixEntry, VixExit, and trade outcomes:\")\n",
        "print(correlation_matrix)\n"
      ],
      "metadata": {
        "id": "M-Gzo85uKpk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5 Time-Based Analysis**\n",
        "\n",
        "Analyze the performance of trades based on Date or Day.\n",
        "--Step 1: Analyze Performance by Date or Day\n",
        "Convert the Date column to a datetime object using pd.to_datetime().\n",
        "Group data by Date or day of the week and calculate metrics like total profit/loss and trade count.\n",
        "\n",
        "---Evaluate the average time a trade was open by calculating the difference between Entry_Time and Exit_Time.\n",
        "\n",
        "Ensure Entry_Time and Exit_Time are in the correct datetime format.\n",
        "Calculate the difference between Exit_Time and Entry_Time for each trade.\n",
        "Convert the duration into hours or minutes and find the average holding tim"
      ],
      "metadata": {
        "id": "mDjIRmD_LlIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/trading_data.csv')\n",
        "\n",
        "# Ensure date and time columns are properly parsed\n",
        "data['Entry_Time'] = pd.to_datetime(data['Entry_Time'], errors='coerce', format='mixed')\n",
        "data['Exit_Time'] = pd.to_datetime(data['Exit_Time'], errors='coerce', format='mixed')\n",
        "data['Date'] = data['Entry_Time'].dt.date\n",
        "\n",
        "# Drop rows with invalid datetime parsing\n",
        "data = data.dropna(subset=['Entry_Time', 'Exit_Time'])\n",
        "\n",
        "# Analyze performance based on Date\n",
        "data['Profit/Loss'] = (data['Exit_Price'] - data['Entry_Price']) * data['Quantity']\n",
        "performance_by_date = data.groupby('Date')['Profit/Loss'].mean()\n",
        "print(\"\\nPerformance by Date (mean profit/loss):\")\n",
        "print(performance_by_date)\n",
        "\n",
        "# Analyze performance based on Day of the week\n",
        "data['Day'] = data['Entry_Time'].dt.day_name()\n",
        "performance_by_day = data.groupby('Day')['Profit/Loss'].mean()\n",
        "print(\"\\nPerformance by Day (mean profit/loss):\")\n",
        "print(performance_by_day)\n",
        "\n",
        "# Calculate the average time a trade was open\n",
        "data['Trade_Duration'] = (data['Exit_Time'] - data['Entry_Time']).dt.total_seconds() / 60  # Duration in minutes\n",
        "average_trade_duration = data['Trade_Duration'].mean()\n",
        "\n",
        "print(f\"\\nAverage trade duration: {average_trade_duration:.2f} minutes\")\n"
      ],
      "metadata": {
        "id": "dJM6drr-LlZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.Volatility Impact**\n",
        "\n",
        "Compare Entry_imp_vol and Exit_imp_vol to understand the impact of implied volatility changes on trade outcomes.\n",
        "Step 1: Analyze the Impact of Implied Volatility (Entry_imp_vol vs. Exit_imp_vol)\n",
        "Compare Entry_imp_vol and Exit_imp_vol for profitable vs. losing trades:\n",
        "Calculate the mean and standard deviation of Entry_imp_vol and Exit_imp_vol for both profitable and losing trades.\n",
        "Analyze whether a significant change in implied volatility corresponds to profitable trades.\n",
        "\n",
        "Analyze how Entry_delta and Exit_delta shifted in profitable vs. losing trades.\n",
        "--Step 2: Analyze Entry_delta and Exit_delta for Profitable vs. Losing Trades\n",
        "Calculate the mean and standard deviation of Entry_delta and Exit_delta for profitable and losing trades.\n",
        "Compare the shifts in deltas between the two groups to identify patterns."
      ],
      "metadata": {
        "id": "9RSxVOJARSNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/trading_data.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Calculate Profit/Loss for each trade\n",
        "df['Profit_Loss'] = (df['Exit_Price'] - df['Entry_Price']) * df['Quantity']\n",
        "\n",
        "# Separate profitable and losing trades\n",
        "profitable_trades = df[df['Profit_Loss'] > 0]\n",
        "losing_trades = df[df['Profit_Loss'] <= 0]\n",
        "\n",
        "# Calculate stats for implied volatility\n",
        "vol_stats = {\n",
        "    \"Profitable Trades\": {\n",
        "        \"Avg_Entry_imp_vol\": profitable_trades['Entry_imp_vol'].mean(),\n",
        "        \"Avg_Exit_imp_vol\": profitable_trades['Exit_imp_vol'].mean(),\n",
        "    },\n",
        "    \"Losing Trades\": {\n",
        "        \"Avg_Entry_imp_vol\": losing_trades['Entry_imp_vol'].mean(),\n",
        "        \"Avg_Exit_imp_vol\": losing_trades['Exit_imp_vol'].mean(),\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"Implied Volatility Analysis:\")\n",
        "print(vol_stats)\n",
        "# Calculate stats for delta\n",
        "delta_stats = {\n",
        "    \"Profitable Trades\": {\n",
        "        \"Avg_Entry_delta\": profitable_trades['Entry_delta'].mean(),\n",
        "        \"Avg_Exit_delta\": profitable_trades['Exit_delta'].mean(),\n",
        "    },\n",
        "    \"Losing Trades\": {\n",
        "        \"Avg_Entry_delta\": losing_trades['Entry_delta'].mean(),\n",
        "        \"Avg_Exit_delta\": losing_trades['Exit_delta'].mean(),\n",
        "    }\n",
        "}\n",
        "\n",
        "# Print the delta analysis\n",
        "print(\"Delta Analysis:\")\n",
        "print(delta_stats)\n"
      ],
      "metadata": {
        "id": "asoGjswfRSXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.Statistical Insights\n",
        "\n",
        "Conduct a regression analysis to evaluate the relationship between IndexEntrySpot and IndexExitSpot.\n",
        "--Step 1: Regression Analysis Between IndexEntrySpot and IndexExitSpot\n",
        "Perform a simple linear regression to analyze the relationship between IndexEntrySpot and IndexExitSpot.\n",
        "Use scipy.stats or statsmodels to calculate the regression coefficient, p-value, and R-squared to determine the strength of the relationship.\n",
        "\n",
        "\n",
        "Use statistical formulas to determine if there's a significant difference in profit/loss between Expiry and Non-Expiry trades.\n",
        "--Step 2: Compare Profit/Loss Between Expiry and Non-Expiry Trades\n",
        "Categorize trades into \"Expiry\" and \"Non-Expiry\" based on the Expiry column.\n",
        "Use a statistical test (e.g., a two-sample t-test) to determine if there’s a significant difference in Profit_Loss between these categories."
      ],
      "metadata": {
        "id": "9zrcgyzQS5Jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import linregress\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure columns are numeric, replacing invalid entries with NaN\n",
        "df['IndexEntrySpot'] = pd.to_numeric(df['IndexEntrySpot'], errors='coerce')\n",
        "df['IndexExitSpot'] = pd.to_numeric(df['IndexExitSpot'], errors='coerce')\n",
        "\n",
        "# Drop rows with NaN values in these columns\n",
        "cleaned_df = df.dropna(subset=['IndexEntrySpot', 'IndexExitSpot'])\n",
        "\n",
        "# Perform regression if enough data exists\n",
        "if not cleaned_df.empty:\n",
        "    slope, intercept, r_value, p_value, std_err = linregress(\n",
        "        cleaned_df['IndexEntrySpot'], cleaned_df['IndexExitSpot']\n",
        "    )\n",
        "    print(\"Regression Analysis:\")\n",
        "    print(f\"Slope: {slope:.2f}\")\n",
        "    print(f\"Intercept: {intercept:.2f}\")\n",
        "    print(f\"R-squared: {r_value**2:.2f}\")\n",
        "    print(f\"P-value: {p_value:.2e}\")\n",
        "else:\n",
        "    print(\"Insufficient valid data for regression analysis.\")\n",
        "\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Ensure 'Profit_Loss' column is calculated\n",
        "if 'Profit_Loss' not in df.columns:\n",
        "    df['Profit_Loss'] = (df['Exit_Price'] - df['Entry_Price']) * df['Quantity']\n",
        "\n",
        "# Map 'Expiry/Non Expiry' to boolean values for filtering\n",
        "df['Expiry'] = df['Expiry/Non Expiry'].map({'Expiry': True, 'Non Expiry': False})\n",
        "\n",
        "# Separate trades into Expiry and Non-Expiry categories\n",
        "expiry_trades = df[df['Expiry'] == True]['Profit_Loss']\n",
        "non_expiry_trades = df[df['Expiry'] == False]['Profit_Loss']\n",
        "\n",
        "# Perform the t-test\n",
        "t_stat, p_value = ttest_ind(expiry_trades, non_expiry_trades, equal_var=False)\n",
        "\n",
        "# Print the results\n",
        "print(\"T-test for Expiry vs Non-Expiry Trades:\")\n",
        "print(f\"T-statistic: {t_stat:.2f}\")\n",
        "print(f\"P-value: {p_value:.2e}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"Significant difference in Profit/Loss between Expiry and Non-Expiry trades.\")\n",
        "else:\n",
        "    print(\"No significant difference in Profit/Loss between Expiry and Non-Expiry trades.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ld3nPobKSyOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.Risk and Reward\n",
        "\n",
        "--Compute the risk/reward ratio for each trade using SL% and Trgt%.\n",
        "\n",
        "Step 1: Compute Risk/Reward Ratio for Each Trade\n",
        "Use SL% (Stop Loss percentage) and Trgt% (Target percentage) to compute the risk/reward ratio for each trade\n",
        "Add a new column in the dataset to store the calculated ratio.\n",
        "\n",
        "--Analyze how SL_move influenced trade outcomes.\n",
        "Step 2: Analyze the Impact of SL_move on Trade Outcomes\n",
        "Separate trades into two groups: those with SL_move adjustments and those without.\n",
        "Compare the average Profit_Loss between the two groups.\n",
        "Identify if SL_move improved or worsened trade outcom"
      ],
      "metadata": {
        "id": "WrXj9Ms6Uznw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Risk/Reward ratio for every trade\n",
        "df['Risk_Reward_Ratio'] = df['SL%'] / df['Trgt%']\n",
        "\n",
        "# Display the first few rows with the calculated Risk/Reward ratio\n",
        "print(\"Risk/Reward Ratio for Each Trade:\")\n",
        "print(df[['SL%', 'Trgt%', 'Risk_Reward_Ratio']].head())\n",
        "\n",
        "# Add a new column to indicate if SL_move influenced the outcome\n",
        "df['SL_Move_Impact'] = df['SL_move'] > 0\n",
        "\n",
        "# Analyze how SL_move influenced trade outcomes\n",
        "sl_move_analysis = df.groupby('SL_Move_Impact')['Profit_Loss'].mean().to_dict()\n",
        "\n",
        "# Print detailed trade analysis based on SL_move\n",
        "print(\"\\nImpact of SL Move on Trade Outcomes (for every trade):\")\n",
        "print(\"Average Profit/Loss by SL Move:\")\n",
        "for sl_move, avg_profit in sl_move_analysis.items():\n",
        "    sl_move_status = \"SL Moved\" if sl_move else \"No SL Movement\"\n",
        "    print(f\"{sl_move_status}: {avg_profit:.2f}\")\n",
        "\n",
        "# Display the first few rows to verify added columns\n",
        "print(\"\\nUpdated Data with SL_Move_Impact and Risk/Reward Ratio:\")\n",
        "print(df[['SL%', 'Trgt%', 'Risk_Reward_Ratio', 'SL_Move_Impact', 'Profit_Loss']].head())\n"
      ],
      "metadata": {
        "id": "xP0K-5yDUz0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.Instrument Comparison\n",
        "\n",
        "--Compare the performance of InstrumentLeg for Call (CE) vs. Put (PE) trades.\n",
        "Step 1: Compare Performance of InstrumentLeg for Call (CE) vs. Put (PE)\n",
        "Filter the dataset into two subsets:\n",
        "Trades with InstrumentLeg as Call (CE).\n",
        "Trades with InstrumentLeg as Put (PE).\n",
        "Calculate the average Profit_Loss for both subsets.\n",
        "Analyze which instrument performed better overall.\n",
        "\n",
        "\n",
        "--Determine if ce_strike trades performed better than pe_strike trades.\n",
        "Step 2: Compare Performance of ce_strike vs. pe_strike Trades\n",
        "Identify trades involving ce_strike and pe_strike.\n",
        "Calculate the total and average profit/loss for these trades.\n",
        "Determine if ce_strike or pe_strike performed better\n"
      ],
      "metadata": {
        "id": "SnfMdJSebSVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter trades by InstrumentLeg\n",
        "call_trades = df[df['InstrumentLeg'] == 'CE']\n",
        "put_trades = df[df['InstrumentLeg'] == 'PE']\n",
        "\n",
        "# Calculate average profit/loss for each instrument\n",
        "instrument_comparison = {\n",
        "    \"Call Trades (CE)\": call_trades['Profit_Loss'].mean(),\n",
        "    \"Put Trades (PE)\": put_trades['Profit_Loss'].mean(),\n",
        "}\n",
        "\n",
        "print(\"Instrument Comparison (CE vs. PE):\")\n",
        "print(instrument_comparison)\n",
        "\n",
        "# Check for missing values in ce_strike and pe_strike before filtering\n",
        "if 'ce_strike' in df.columns and 'pe_strike' in df.columns:\n",
        "    ce_strike_trades = df[df['ce_strike'].notna()]\n",
        "    pe_strike_trades = df[df['pe_strike'].notna()]\n",
        "\n",
        "    # Calculate performance metrics for CE and PE strike trades\n",
        "    strike_comparison = {\n",
        "        \"CE Strike Trades\": {\n",
        "            \"Total Profit/Loss\": ce_strike_trades['Profit_Loss'].sum(),\n",
        "            \"Average Profit/Loss\": ce_strike_trades['Profit_Loss'].mean(),\n",
        "        },\n",
        "        \"PE Strike Trades\": {\n",
        "            \"Total Profit/Loss\": pe_strike_trades['Profit_Loss'].sum(),\n",
        "            \"Average Profit/Loss\": pe_strike_trades['Profit_Loss'].mean(),\n",
        "        },\n",
        "    }\n",
        "\n",
        "    print(\"Strike Comparison (CE vs. PE):\")\n",
        "    print(strike_comparison)\n",
        "else:\n",
        "    print(\"Columns 'ce_strike' or 'pe_strike' not found in the dataset.\")\n"
      ],
      "metadata": {
        "id": "zCOQ3lSTbSmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.Charts and Dashboards\n",
        "\n",
        "Create a chart showing the performance of different Strategies over time.\n",
        "Develop a dashboard to monitor key metrics like success rate, average profit/loss, and strategy performance.\n",
        "\n",
        "Chart:\n",
        "Here’s how the dashboard works:\n",
        "\n",
        "Data Loading & Processing:\n",
        "\n",
        "The dataset is read into a DataFrame.\n",
        "Profit/Loss is calculated for each trade based on entry/exit prices, quantity, and direction (Buy/Sell).\n",
        "Key Metrics:\n",
        "\n",
        "Metrics like success rate, average profit/loss, total profit/loss, and total trades are computed for each strategy.\n",
        "Interactive Dashboard:\n",
        "\n",
        "Filters: Dropdown for selecting a strategy and a date range picker.\n",
        "Dynamic Charts:\n",
        "Line chart shows strategy performance over time.\n",
        "Bar chart displays daily profit/loss.\n",
        "Callbacks:\n",
        "\n",
        "User interactions (selecting strategy or date range) trigger a callback to filter data and update metrics/charts.\n",
        "Execution:\n",
        "\n",
        "The dashboard is hosted using jupyter-dash and runs interactively within the Colab notebook.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LJyvjogZb5S6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas plotly dash jupyter-dash\n"
      ],
      "metadata": {
        "id": "JdMtcpFBb5go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from jupyter_dash import JupyterDash\n",
        "from dash import dcc, html, Input, Output\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "file_path = '/content/trading_data.csv'  # Update to your uploaded file's path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df['Direction'] = df['Direction'].map({'Buy': 1, 'Sell': -1})\n",
        "df['Profit_Loss'] = (df['Exit_Price'] - df['Entry_Price']) * df['Quantity'] * df['Direction']\n",
        "\n",
        "# Key metrics calculations\n",
        "key_metrics = df.groupby('Strategy').agg(\n",
        "    Success_Rate=('Profit_Loss', lambda x: (x > 0).mean() * 100),\n",
        "    Avg_Profit_Loss=('Profit_Loss', 'mean'),\n",
        "    Total_Profit_Loss=('Profit_Loss', 'sum'),\n",
        "    Total_Trades=('Profit_Loss', 'count')\n",
        ").reset_index()\n",
        "\n",
        "strategy_performance = df.groupby(['Strategy', 'Date'])['Profit_Loss'].sum().reset_index()\n",
        "\n",
        "# Initialize JupyterDash app\n",
        "app = JupyterDash(__name__)\n",
        "\n",
        "# App layout\n",
        "app.layout = html.Div([\n",
        "    html.H1(\"Trading Strategy Dashboard\", style={'text-align': 'center'}),\n",
        "\n",
        "    # Dropdown for strategy selection\n",
        "    html.Div([\n",
        "        html.Label(\"Select Strategy:\"),\n",
        "        dcc.Dropdown(\n",
        "            id='strategy-dropdown',\n",
        "            options=[{'label': s, 'value': s} for s in df['Strategy'].unique()],\n",
        "            value=df['Strategy'].unique()[0],\n",
        "            multi=False\n",
        "        ),\n",
        "    ], style={'margin-bottom': '20px'}),\n",
        "\n",
        "    # Date range picker\n",
        "    html.Div([\n",
        "        html.Label(\"Select Date Range:\"),\n",
        "        dcc.DatePickerRange(\n",
        "            id='date-picker',\n",
        "            start_date=df['Date'].min(),\n",
        "            end_date=df['Date'].max(),\n",
        "            display_format='YYYY-MM-DD'\n",
        "        )\n",
        "    ], style={'margin-bottom': '20px'}),\n",
        "\n",
        "    # Output key metrics\n",
        "    html.Div(id='key-metrics-output', style={'margin-bottom': '20px'}),\n",
        "\n",
        "    # Charts\n",
        "    dcc.Graph(id='performance-chart'),\n",
        "    dcc.Graph(id='metrics-chart')\n",
        "])\n",
        "\n",
        "# Callbacks for interactivity\n",
        "@app.callback(\n",
        "    [Output('key-metrics-output', 'children'),\n",
        "     Output('performance-chart', 'figure'),\n",
        "     Output('metrics-chart', 'figure')],\n",
        "    [Input('strategy-dropdown', 'value'),\n",
        "     Input('date-picker', 'start_date'),\n",
        "     Input('date-picker', 'end_date')]\n",
        ")\n",
        "def update_dashboard(selected_strategy, start_date, end_date):\n",
        "    # Filter data\n",
        "    filtered_data = df[\n",
        "        (df['Strategy'] == selected_strategy) &\n",
        "        (df['Date'] >= pd.to_datetime(start_date)) &\n",
        "        (df['Date'] <= pd.to_datetime(end_date))\n",
        "    ]\n",
        "\n",
        "    # Update key metrics\n",
        "    success_rate = (filtered_data['Profit_Loss'] > 0).mean() * 100\n",
        "    avg_profit_loss = filtered_data['Profit_Loss'].mean()\n",
        "    total_profit_loss = filtered_data['Profit_Loss'].sum()\n",
        "    total_trades = filtered_data['Profit_Loss'].count()\n",
        "\n",
        "    key_metrics_output = html.Div([\n",
        "        html.H4(f\"Key Metrics for {selected_strategy}:\"),\n",
        "        html.P(f\"Success Rate: {success_rate:.2f}%\"),\n",
        "        html.P(f\"Average Profit/Loss: {avg_profit_loss:.2f}\"),\n",
        "        html.P(f\"Total Profit/Loss: {total_profit_loss:.2f}\"),\n",
        "        html.P(f\"Total Trades: {total_trades}\")\n",
        "    ])\n",
        "\n",
        "    # Update performance chart\n",
        "    performance_data = strategy_performance[\n",
        "        (strategy_performance['Strategy'] == selected_strategy) &\n",
        "        (strategy_performance['Date'] >= pd.to_datetime(start_date)) &\n",
        "        (strategy_performance['Date'] <= pd.to_datetime(end_date))\n",
        "    ]\n",
        "    performance_fig = px.line(\n",
        "        performance_data,\n",
        "        x='Date',\n",
        "        y='Profit_Loss',\n",
        "        title=f\"Performance Over Time ({selected_strategy})\",\n",
        "        labels={'Profit_Loss': 'Profit/Loss', 'Date': 'Date'}\n",
        "    )\n",
        "\n",
        "    # Update metrics chart\n",
        "    metrics_data = filtered_data.groupby(['Strategy', 'Date'])['Profit_Loss'].sum().reset_index()\n",
        "    metrics_fig = px.bar(\n",
        "        metrics_data,\n",
        "        x='Date',\n",
        "        y='Profit_Loss',\n",
        "        color='Strategy',\n",
        "        title=\"Daily Profit/Loss\",\n",
        "        labels={'Profit_Loss': 'Profit/Loss', 'Date': 'Date'}\n",
        "    )\n",
        "\n",
        "    return key_metrics_output, performance_fig, metrics_fig\n",
        "\n",
        "# Run the app in Colab\n",
        "app.run_server(mode='inline')\n"
      ],
      "metadata": {
        "id": "SgsZxuTSdElH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.Error Detection\n",
        "\n",
        "Identify any anomalies or outliers in the data (e.g., trades with extremely high or low profits).\n",
        "Discuss how you would validate if Entry_PCR and Exit_PCR values align with market conditions.\n",
        "\n",
        "12.Optimization Suggestions\n",
        "\n",
        "Based on your analysis, suggest ways to optimize SL, Target, or entry/exit conditions to improve the strategy’s performance.\n",
        "\n",
        "\n",
        "--Error Detection & Outlier Analysis:\n",
        "\n",
        "Identifies outliers in Profit_Loss using the 3-sigma rule.\n",
        "Detects anomalies in Entry_PCR and Exit_PCR values based on predefined thresholds.\n",
        "SL% and Target% Analysis:\n",
        "\n",
        "Compares Stop Loss (SL%) and Target (Trgt%) between winning and losing trades.\n",
        "Computes correlations between Entry_delta, Exit_delta, and Profit_Loss.\n",
        "Visualizations:\n",
        "\n",
        "Boxplots and scatterplots to highlight outliers, PCR trends, and deltas' impact.\n",
        "Optimization Suggestions:\n",
        "\n",
        "Summarizes actionable strategies to improve performance based on the analysis."
      ],
      "metadata": {
        "id": "JUrN1RfVk9LP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/trading_data.csv'  # Adjust this path if needed\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocess data\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df['Direction'] = df['Direction'].map({'Buy': 1, 'Sell': -1})\n",
        "df['Profit_Loss'] = (df['Exit_Price'] - df['Entry_Price']) * df['Quantity'] * df['Direction']\n",
        "\n",
        "# Define function for error detection and analysis\n",
        "def error_detection_analysis(data):\n",
        "    print(\"=== Error Detection ===\")\n",
        "    # Calculate mean and standard deviation\n",
        "    mean_profit_loss = data['Profit_Loss'].mean()\n",
        "    std_profit_loss = data['Profit_Loss'].std()\n",
        "\n",
        "    # Define outlier thresholds\n",
        "    lower_bound = mean_profit_loss - 3 * std_profit_loss\n",
        "    upper_bound = mean_profit_loss + 3 * std_profit_loss\n",
        "\n",
        "    # Identify outliers\n",
        "    outliers = data[(data['Profit_Loss'] < lower_bound) | (data['Profit_Loss'] > upper_bound)]\n",
        "    print(f\"Outliers detected: {len(outliers)}\")\n",
        "    print(outliers)\n",
        "\n",
        "    # Visualize with a boxplot\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.boxplot(x=data['Profit_Loss'])\n",
        "    plt.title('Boxplot of Profit/Loss to Identify Outliers')\n",
        "    plt.show()\n",
        "\n",
        "    # Check for anomalies in PCR values\n",
        "    anomalous_pcr = data[(data['Entry_PCR'] < 0) | (data['Exit_PCR'] < 0) |\n",
        "                         (data['Entry_PCR'] > 10) | (data['Exit_PCR'] > 10)]\n",
        "    print(f\"Anomalies in PCR values: {len(anomalous_pcr)}\")\n",
        "    print(anomalous_pcr)\n",
        "\n",
        "    # PCR trends visualization\n",
        "    sns.scatterplot(data=data, x='Entry_PCR', y='Profit_Loss', hue='Strategy')\n",
        "    plt.title('Entry_PCR vs. Profit/Loss')\n",
        "    plt.show()\n",
        "\n",
        "    sns.scatterplot(data=data, x='Exit_PCR', y='Profit_Loss', hue='Strategy')\n",
        "    plt.title('Exit_PCR vs. Profit/Loss')\n",
        "    plt.show()\n",
        "\n",
        "# Analyze SL%, Target%, and deltas\n",
        "def analyze_sl_target(data):\n",
        "    print(\"=== SL and Target Analysis ===\")\n",
        "    # Winning vs Losing trades\n",
        "    winning_trades = data[data['Profit_Loss'] > 0]\n",
        "    losing_trades = data[data['Profit_Loss'] <= 0]\n",
        "\n",
        "    avg_sl_winning = winning_trades['SL%'].mean()\n",
        "    avg_trgt_winning = winning_trades['Trgt%'].mean()\n",
        "    avg_sl_losing = losing_trades['SL%'].mean()\n",
        "    avg_trgt_losing = losing_trades['Trgt%'].mean()\n",
        "\n",
        "    print(f\"Average SL% in Winning Trades: {avg_sl_winning:.2f}\")\n",
        "    print(f\"Average Target% in Winning Trades: {avg_trgt_winning:.2f}\")\n",
        "    print(f\"Average SL% in Losing Trades: {avg_sl_losing:.2f}\")\n",
        "    print(f\"Average Target% in Losing Trades: {avg_trgt_losing:.2f}\")\n",
        "\n",
        "    # Correlation analysis\n",
        "    corr_entry = data['Entry_delta'].corr(data['Profit_Loss'])\n",
        "    corr_exit = data['Exit_delta'].corr(data['Profit_Loss'])\n",
        "\n",
        "    print(f\"Correlation between Entry_delta and Profit_Loss: {corr_entry:.2f}\")\n",
        "    print(f\"Correlation between Exit_delta and Profit_Loss: {corr_exit:.2f}\")\n",
        "\n",
        "    # Visualize delta impact on profits\n",
        "    sns.scatterplot(data=data, x='Entry_delta', y='Profit_Loss')\n",
        "    plt.title('Entry_delta vs Profit/Loss')\n",
        "    plt.show()\n",
        "\n",
        "    sns.scatterplot(data=data, x='Exit_delta', y='Profit_Loss')\n",
        "    plt.title('Exit_delta vs Profit/Loss')\n",
        "    plt.show()\n",
        "\n",
        "# Optimization suggestions\n",
        "def suggest_optimizations(data):\n",
        "    print(\"=== Optimization Suggestions ===\")\n",
        "    print(\"- Adjust SL% to average levels for winning trades.\")\n",
        "    print(\"- Focus on trades where PCR values align with historically profitable ranges.\")\n",
        "    print(\"- Analyze and optimize trades based on Entry/Exit deltas with high positive correlations.\")\n",
        "    print(\"- Prioritize instruments or strategies with consistently higher success rates.\")\n",
        "\n",
        "# Run the functions\n",
        "error_detection_analysis(df)\n",
        "analyze_sl_target(df)\n",
        "suggest_optimizations(df)\n"
      ],
      "metadata": {
        "id": "jyWE3TN4k9Wn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}